<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=0" >
<link rel="stylesheet" type="text/css" href="style.css">
<base target="_blank">
<title>Anıl Çamcı</title>
</head>

<script src="imagesloaded.pkgd.min.js"></script>

<script>
	function resizeGridItem(item){
	  grid = document.getElementsByClassName("grid")[0];
	  rowHeight = parseInt(window.getComputedStyle(grid).getPropertyValue('grid-auto-rows'));
	  rowGap = parseInt(window.getComputedStyle(grid).getPropertyValue('grid-row-gap'));
	  rowSpan = Math.ceil((item.querySelector('.content').getBoundingClientRect().height+rowGap)/(rowHeight+rowGap));
	  item.style.gridRowEnd = "span "+rowSpan;
	}

	function resizeAllGridItems(){
	  allItems = document.getElementsByClassName("work-container");
	  for(x=0;x<allItems.length;x++){
	    resizeGridItem(allItems[x]);
	  }
	}

	function resizeInstance(instance){
		item = instance.elements[0];
	  resizeGridItem(item);
	}

	window.onload = resizeAllGridItems();
	window.addEventListener("resize", resizeAllGridItems);
	document.addEventListener("DOMContentLoaded", function(e) {
		allItems = document.getElementsByClassName("work-container");
		for(x=0;x<allItems.length;x++){
			imagesLoaded(allItems[x], resizeInstance);
		}
	});


</script>

<body>

	<div class="topbar">
	  <div id="title">Anıl Çamcı</div>
		<!-- <div id="menu-container">
			<div id="menu">
			<span class="active">Spotlight</span>
			<span class="inactive"><a href="art.html">Art</a></span>
			<span class="inactive"><a href="research.html">Research</a></span>
			</div>
		</div> -->
	</div>

	<div id="bio-container">
	  I am an Assistant Professor of <a
	  href="https://smtd.umich.edu/pat/">Performing Arts Technology</a> at the
	  University of Michigan. I investigate ways of worldmaking through multimedia
	  artworks and research in the areas of virtual reality, human-computer
	  interaction, and spatial audio. Before joining the University of Michigan, I
	  was a Postdoctoral Research Associate at the University of Illinois at
	  Chicago's <a href="https://www.evl.uic.edu">Electronic Visualization
	  Laboratory</a>, where I led research into immersive systems. Prior to this
	  appointment, I was a faculty member of the Istanbul Technical University,
	  Center for Advanced Studies in Music, where I founded the <a
	  href="https://www.facebook.com/MiamSonicArts/">Sonic Arts Program</a>. I
	  conducted my PhD research at Leiden University's <a
	  href="https://www.universiteitleiden.nl/en/humanities/academy-of-creative-and-performing-arts">Academy
	  of Creative and Performing Arts</a>, in affiliation with the <a
	  href="http://www.sonology.org">Institute of Sonology</a> in The Hague, and
	  the <a href="https://www.tudelft.nl/en/ide/">Industrial Design
	  Department</a> at Delft University of Technology. I studied Multimedia
	  Engineering at the University of California, Santa Barbara's <a
	  href="https://www.mat.ucsb.edu">Media Arts and Technology Department</a>. My
	  works have been featured throughout the world in leading journals and
	  conferences. I have been awarded various grants and scholarships including
	  the Audio Engineering Society Fellowship and the ACM CHI Artist Grant.
	</div>

	<div class="grid">

		<div class="work-container">
			<div class="content">
				<img id="work-image" src="media/trust.png">
				<div id="work-title">Who do you trust in VR?<span style="font-size: 0.8rem; vertical-align: middle;"> [2019]</span> </div>
				<div id="work-description-container">
					Auditory and visual cues that make up the user interface of a VR help
					users make decisions on how to proceed in a virtual scenario. These
					interfaces can be diegetic (i.e. presented as part of the VR) or
					non-diegetic (i.e. presented as an external layer superimposed onto
					the VR). This project explores how auditory and visual cues of
					diegetic and non-diegetic origins affect a user’s decision-making
					process in VR.
					<br><br><a href="publications/Camci_2019_SMC.pdf">SMC Paper</a>
				</div>
			</div>
		</div>

		<div class="work-container">
			<div class="content">
				<img id="work-image" src="media/hyperreal.png">
				<div id="work-title">Hyperreal Instruments<span style="font-size: 0.8rem; vertical-align: middle;"> [2019]</span> </div>
				<div id="work-description-container">
					The Hyperreal Instruments Project bridges VR and digital fabrication toward the design of new
					virtual instruments that can defy our sense of audiovisual reality
					while satisfying our proprioceptive and haptic expectations. In doing
					so, the project aims to identify the unique affordances of VR for
					musical expression.

					<br><br><a href="https://www.mitpressjournals.org/doi/abs/10.1162/lmj_a_01056">Leonardo Music Journal Paper</a>
				</div>
			</div>
		</div>

		<div class="work-container">
			<div class="content">
				<img id="work-image" src="media/alarmVR.png">
				<div id="work-title">AlarmVR<span style="font-size: 0.8rem; vertical-align: middle;"> [2019]</span> </div>
				<div id="work-description-container">
					This project employs VR and immersive audio to identify and address
					the underlying auditory causes of one of the top patient safety
					hazards in clinical environments, namely alarm fatigue, which is a
					form of sensory overload that causes healthcare professionals to be
					desensitized towards alarm events due to extended exposure.
					<br><br><a href="https://mcubed.umich.edu/projects/alarmvr-investigating-alarm-fatigue-clinical-environments-using-immersive-audio-and">Project Website</a>
				</div>
			</div>
		</div>

		<div class="work-container">
			<div class="content">
				<img id="work-image" src="media/vylderness.jpg">
				<div id="work-title">Vylderness<span style="font-size: 0.8rem; vertical-align: middle;"> [2019]</span> </div>
				<div id="work-description-container">
					Vylderness is an upcoming Virtual Reality and Modular Synthesis
					performance that brings the audience into a narrative audiovisual
					experience driven by live electronic music. The 3 gamified stories
					that make up the work, namely "Finding Me", "Affordances" and "The
					Vyld", are intertwined both conceptually and spatially.
				</div>
			</div>
		</div>

		<div class="work-container">
			<div class="content">
				<img id="work-image" src="media/inviso.png">
				<div id="work-title">Inviso<span style="font-size: 0.8rem; vertical-align: middle;"> [2017-2019]</span> </div>
				<div id="work-description-container">
					Inviso is a web-based application for designing and experiencing rich
					and dynamic sonic virtual realities. It enables both novice and expert
					users to construct complex immersive sonic environments with 3D
					dynamic sound components.

					<br><br><a href="http://inviso.cc">http://inviso.cc</a> • <a href="publications/Camci_2017_UIST_Inviso.pdf">UIST Paper</a>
				</div>
			</div>
		</div>

		<div class="work-container">
			<div class="content">
				<div id="work-title">Future of Audio in VR<span style="font-size: 0.8rem; vertical-align: middle;"> [2018-2019]</span> </div>
				<div id="work-description-container">
					These series of workshops aim to bring VR researchers and
					practicioners from a wide range of backgrounds together to specify the ways
					in which we can think natively about VR audio and articulate the role
					of sound in the ultimate displays of the future. The workshops
					not only highlight recent developments in VR audio, but also
					identify the needs of the VR community in creating compelling virtual
					auditory experiences for the next generation of immersive media.
					<br><br><a href="https://favr2019.github.io">IEEE VR Workshop Website</a> • <a href="https://audio1stVR.github.io">NIME Workshop Website</a>
				</div>
			</div>
		</div>

		<div class="work-container">
			<div class="content">
				<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/252820148?title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>
				<div id="work-title">GrainTrain<span style="font-size: 0.8rem; vertical-align: middle;"> [2018]</span> </div>
				<div id="work-description-container">
					GrainTrain is an innovative multi-touch performance tool for real-time
					granular synthesis based on hand-drawn waveforms. It is a
					cross-platform web application that can run on both desktop and mobile
					computers, including tablets and phones.

					<br><br><a href="http://graintra.in">http://graintra.in</a> • <a href="publications/Camci_2018_NIME_GrainTrain.pdf">NIME Paper</a>
				</div>
			</div>
		</div>

		<div class="work-container">
			<div class="content">

				<iframe width="100%" height="125" scrolling="no" frameborder="no"
				allow="autoplay"
				src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/634242198%3Fsecret_token%3Ds-0axNL&color=e2e2e2&amp&auto_play=false&hide_related=true&show_comments=false&show_user=false&show_reposts=false&show_teaser=false&show_artwork=false"></iframe>

				<div id="work-title">A Now Unknown (Excerpt) <span style="font-size: 0.8rem; vertical-align: middle;"> [2018]</span> </div>
				<div id="work-description-container">
					Weaving 40 performances with a modular synthesizer from a 2-year span, A Now
					Unknown traverses the middle ground between the indeterminacy of the modular
					medium, and the undulating path that is a composer's plan. The turns of the same
					knob––days, months and years apart––are frozen and juxtaposed into an abundance
					of once present moments; a bricolage of nows that are impossible to tell when.
				</div>
			</div>
		</div>

		<div class="work-container">
			<div class="content">
				<img id="work-image" src="media/synthCity.jpg">
				<div id="work-title">Synthcity<span style="font-size: 0.8rem; vertical-align: middle;"> [2015-2018]</span> </div>
				<div id="work-description-container">
					Synthcity is an audiovisual performance. By computationally blending
					everyday figures and textures, it synthesizes extremely unrealistic
					versions of a city using its real landscapes, objects, sounds and
					people. Synthcity was premiered at ISEA 2017 in Manzales, Colombia.
				</div>
			</div>
		</div>

		<div class="work-container">
			<div class="content">
				<img id="work-image" src="media/temas.png">
				<div id="work-title">Temas<span style="font-size: 0.8rem; vertical-align: middle;"> [2014-2016]</span> </div>
				<div id="work-description-container">
					Temas is a stochastic audiovisual performance that moves the audience
					through an abstract narrative in virtual space. The software
					underlying Temas integrates the artist into a generative system as a
					module of analysis. The most recent version of Temas was premiered at
					the Experimental Sound Studio in Chicago in November 2016.
				</div>
			</div>
		</div>

	</div>

	<div id = "contactDetails">anilcamci.com 2019 • All rights reserved • <a
	href="mailto:anilcamci@gmail.com" style="color:#9bffee">Contact</a></div>

</body>
</html>
